\section{Conclusion} 

This thesis presents a complete way to model HPC applications. With a low overhead framework to collect the data, an analytical model of energy consumption and a heuristic algorithm for multi-phase applications. Each of the methods presented has possible improvements that will be discussed below.


\subsection{Pascal Suite} \label{sec:conclusions_pascal}

The Pascal Suite framework introduces a practical and easy-to-use tools for measuring and analyzing the efficiency of parallel applications. The proposed tool focuses on observing energy consumption and scalability and implements features that enables analysis at hierarchical levels of the program's inner parts. It also simplifies the comparison of the application runs in different configurations, helping developers target software optimization efforts.

The tool has a low level of intrusion added to the program's performance measurement under analysis, which is a fundamental aspect of understanding the program's behavior.

From the results, we observe that the fingerprint module API present overhead similar or lower to other low-level APIs, with the advantage of being in high abstraction and simplified configuration with a few lines of code, is possible to configure and gather performance counter data.

The fingerprint module developed provide also provided a way to compute similarities between different programs or the same program with different inputs. This can be useful to reduce applications spaces for benchmarks as was done in Polybench clustering but also to analyze the behavior of a parameter providing insights to the programmer to find a possible bottleneck.

\textls[-20]{In future work, we intend to evolve this tool to include the ability to predict speedup and efficiency from a few samples using state-of-the-art prediction models present in the \mbox{literature \cite{Alex2020WhenParallelSpeedups, Vitor2022AnalyticalEnergyModel}}. The idea is to present the general behavior of the program and reduce the execution time necessary to compose a comprehensive analysis. Furthermore, we intend to include features that allow the observation of parallel applications in distributed environments that use the Message Passing Interface (MPI) standard.}

\subsection{Application-energy model} \label{sec:conclusion_models}

The proposed energy model based on the frequency and number of cores for a full shared memory system can serve as a base for DVFS and DPM optimization problems that include both frequency and active cores. As well for analysis of the contribution of each parameter (ex: parallelism level) to the energy consumption.

Results from 3 HPC benchmarks running in one cluster demonstrate the potential of the proposed novel model. While consuming less energy than traditional machine learning approaches, it can serve as bases from DVFS and DPM algorithm as shown in the \ref{sec:model_validation} in an average case saving about 12\% up to 69\%. The previous knowledge of the application's performance can expose sufficiently relevant information, such as parallel speedups, that is harder to guess in run-time techniques based on DVFS.

A weakness of the proposed model is the need for information about the input size of the application that can be complex to derive. A possible solution would be to precisely define what is input size, given an definition in function of common variable for all applications like throughput for example. Future work will demonstrate all the possible analysis that is possible to archive with the equation as long as more advanced DVFS models that can be derived using the equation. For instance identification of different phases of the target program and thus, it will enable more fine-grained changes of the frequency and, perhaps, the number of active cores, to further improve the results presented here.

Another important aspect that is typically not taken into account is the number of processing cores to be used by a parallel program. This choice is left to the user, which often is not trivial as shown in this thesis.

\subsection{Application-phase heuristic algorithm} \label{sec:phases_conclusion}
The main conclusion of this work was that in the HPC environment, in addition to the advantages of finding the optimal phase divisions, not many phases are needed to achieve the optimal energy consumption. Moreover, an average maximum of 35 phases was sufficient for the three benchmarks used, covering the most varied HPC applications.
It was also possible to notice that there is still a lot to improve in optimizing the DVFS algorithms since we obtained an average of 38\% energy savings compared to Ondemand on Linux.
We also noticed that there is a relation between the application behavior and the phases locations, independently of their number.

For future work, the final idea is to use the information from the best phase to find a performance metric that can provide us with this division without needing data. In future work, we intend to calculate these metrics using a combination of hardware performance counters that allow real-time optimal phase division. This metric can improve current DVFS algorithms by providing them with a workload metric that can improve energy savings.

